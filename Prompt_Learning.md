# <p align="center"> Prompt Learning

## Typology of Prompting Methods
*forked from [NLPedia](https://github.com/pfliu-nlp/NLPedia-Pretrain#answer-engineering-detailed-description)*

### Pre-trained Models (Detailed Description)

- Left-to-right Language Model
- Masked Language Model
- Prefix Language Model
- Encoder-Decoder

### Prompt Engineering (Detailed Description)

- Shape
	- Cloze prompt: 
	- Prefix prompt: 
- Human Effort
	- Hand-crated
	- Automated
		- Discrete: 
		- Continuous: 

### Answer Engineering (Detailed Description)

- Shape
	- Token: 
	- Span: 
	- Sentence: 
- Human Effort
	- Hand-crated: 
	- Automated
		- Discrete: 
		- Continuous: 
### Multi-Prompt Learning (Detailed Description)

- Prompt Ensemble: 
- Prompt Augmentation: 
- Prompt Composition: 
- Prompt Decomposition: 

### Prompt-based Training Strategies (Detailed Description)

- Parameter Updating
	- Promptless Fine-tuning
	- Tuning-free Prompting: 
	- Fixed-LM Prompt Tuning: 
	- Fixed-prompt LM Tuning: 
	- Prompt+LM Tuning: 
- Training Sample Size
	- Zero-shot: 
	- Few-shot: 
	- Full-data: 